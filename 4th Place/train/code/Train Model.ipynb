{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae47a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "from layers import *\n",
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5d4aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path: weights\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 30\n",
    "BATCH_SIZE = 128\n",
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WARMUP_STEPS = 200\n",
    "MOMENTUM = 0.9\n",
    "CLIP_NORM = 15.0\n",
    "\n",
    "TIMELAG = 92\n",
    "H_DIM = 64\n",
    "WIDTH = 92\n",
    "\n",
    "STAGE = 'development'\n",
    "\n",
    "subfolder = Path(\"weights\")\n",
    "subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "MODEL_PATH = subfolder.as_posix()\n",
    "logfile = None\n",
    "print(f\"Model save path: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffb852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seeds(SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59768431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy print option\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=1000);\n",
    "# Seaborn figuresize\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6654c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97741feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = datetime(2014,9,1)\n",
    "\n",
    "labels_2013_2019 = pd.read_csv(\"development/train_labels.csv\", index_col=[0])\n",
    "labels_2020_2021 = pd.read_csv(\"development/labels_2020_2021.csv\", index_col=[0])\n",
    "\n",
    "labels_2013_2019.columns = pd.to_datetime(labels_2013_2019.columns)\n",
    "labels_2020_2021.columns = pd.to_datetime(labels_2020_2021.columns)\n",
    "\n",
    "targets_df = pd.merge(\n",
    "    labels_2013_2019, labels_2020_2021, how = \"outer\", left_index = True, right_index = True)\n",
    "\n",
    "# Targets:\n",
    "# Get datas only with features\n",
    "targets_df = targets_df.loc[:, start_data:]\n",
    "targets_df = targets_df.astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff842b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cell_idx, data_idx for known SWE\n",
    "cell_idx, data_idx = np.nonzero((~np.isnan(targets_df.values)).astype(int))\n",
    "# Convert to cell_id and times\n",
    "target_values = targets_df.values[cell_idx, data_idx].astype(np.float32)\n",
    "cell_idx = targets_df.index[cell_idx]\n",
    "data_idx = pd.to_datetime(targets_df.columns[data_idx])\n",
    "\n",
    "# bin targets\n",
    "binc = np.arange(10, 120, 10)\n",
    "# y, binc = pd.cut(target_values, bins=num_bins, labels=False, retbins=True)\n",
    "y = np.digitize(target_values, bins=binc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4021fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f\"{STAGE}/train_dataset.nc\", engine='netcdf4')\n",
    "ds.load();\n",
    "ds.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4b4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = xr.concat([\n",
    "        (ds.t00 - 273.15) / 10,\n",
    "        (ds.t12 - 273.15) / 10,\n",
    "        (ds.sdwe**0.25 - 1),\n",
    "        (ds.pwat - 8) / 7,\n",
    "        ds.refc / 10,\n",
    "        ds.u / 20,\n",
    "        ds.v / 20,\n",
    "        ds.sdwea,\n",
    "        ds.NDSI,\n",
    "        (ds.sd / 200) - 3.6,\n",
    "    ], dim = 'feature'\n",
    ")\n",
    "\n",
    "band_values = band.ffill('time').fillna(0).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ff8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['t00', 't12', 'sdwe', 'pwat', 'refc', 'u80', 'v80', 'sdwes', 'NDSI', 'sd']\n",
    "\n",
    "xds = xr.Dataset(\n",
    "    data_vars = dict(\n",
    "            band = ([\"feature\", \"time\", \"cell_id\"], band_values),\n",
    "            target = ([\"cell_id\", \"days\"], targets_df.values),\n",
    "            dem = ([\"cell_id\", \"x\", \"y\"], ds.dem.data / 1000 - 2.25),\n",
    "            soil = ([\"cell_id\", \"x\", \"y\"], ds.soil.data),\n",
    "    ),\n",
    "    coords = dict(\n",
    "            feature = FEATURES,\n",
    "            cell_id = ds.coords['cell_id'].data,\n",
    "            days = targets_df.columns,\n",
    "            time = ds.coords['time'].data,\n",
    "        ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2cfd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnowDataset(D.Dataset):\n",
    "\n",
    "    def __init__(self, cells, datas, xds, timelag : int = TIMELAG):\n",
    "        \n",
    "        self.xds = xds\n",
    "        self.datas = datas\n",
    "        self.cells = cells\n",
    "        self.tlag = timedelta(days=timelag)\n",
    "        self.days = timelag\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cells)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        cell_id = self.cells[idx]\n",
    "        data_idx = self.datas[idx]\n",
    "          \n",
    "        features = self.xds.band.loc[\n",
    "            :, data_idx-self.tlag : data_idx-timedelta(1), cell_id].data\n",
    "        \n",
    "        dem_value = self.xds.dem.loc[cell_id].data[None]\n",
    "        soil_value = self.xds.soil.loc[cell_id].data\n",
    "        target = self.xds.target.loc[cell_id, data_idx].data\n",
    "        \n",
    "        return features, dem_value, soil_value, target[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9db987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Table for results\n",
    "header = r'''\n",
    "                  Train | Valid\n",
    "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
    "'''\n",
    "#          Epoch         metrics            time\n",
    "raw_line = '{:6d}' + '\\u2502{:8.3f}'*4 + '\\u2502{:6.2f}'\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(model, loader, loss_fn):\n",
    "    losses = []\n",
    "    yt, yp = [], []\n",
    "    model.eval()\n",
    "    for features, dem, soil, targets in loader:\n",
    "        features = features.float()\n",
    "        dem = dem.float()\n",
    "        soil = soil.long()\n",
    "        targets = targets.float()\n",
    "        outputs = model(features, dem, soil).clamp(0)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        yt.append(targets)\n",
    "        yp.append(outputs)\n",
    "        \n",
    "    yt = torch.cat(yt)\n",
    "    yp = torch.cat(yp)\n",
    "    \n",
    "    return np.array(losses).mean(), yt.numpy(), yp.numpy()\n",
    "\n",
    "def get_figure(yt, yp, binc=binc):\n",
    "    errors = np.abs(yt - yp).squeeze()\n",
    "    xbin = np.digitize(yt, binc).squeeze()\n",
    "    # xbin = np.floor(yt / 10).astype(np.int64)\n",
    "    figure = sns.boxplot(x=xbin, y=errors)\n",
    "    figure.set(ylim=(0, 100), xlim=(-1, 12))\n",
    "    medians = [np.median(errors[xbin == i]) for i in np.unique(xbin)]\n",
    "    vertical_offset = np.median(errors) * 0.4 # offset from median for display\n",
    "\n",
    "    for xtick in figure.get_xticks():\n",
    "        figure.text(xtick, medians[xtick] + vertical_offset, f\"{medians[xtick]:.3f}\", \n",
    "            horizontalalignment='center',size='x-small',color='w',weight='semibold')\n",
    "        \n",
    "    rmse_score = mean_squared_error(yt, yp, squared=False)\n",
    "    figure.annotate(f\"RMSE: {rmse_score:.3f}\", xytext=(0.1, 0.9),\n",
    "            xy=(0.1, 0.9), xycoords=\"axes fraction\", fontsize=12);\n",
    "    \n",
    "    return figure\n",
    "\n",
    "def train_loop(model, optimizer, scheduler, loader, vloader, epoches, fold_idx=0, loss_fn=nn.MSELoss()):\n",
    "    \n",
    "    print(header, file=logfile)\n",
    "\n",
    "    best_metric = np.inf\n",
    "    \n",
    "    for epoch in range(1, epoches+1):\n",
    "        losses = []\n",
    "        yt, yp = [], []\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        for features, dem, soil, targets in loader:\n",
    "            soil = soil.long()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            def closure():\n",
    "                loss = loss_fn(targets, model(features, dem, soil).clamp(0))\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "                return loss\n",
    "            outputs = model(features, dem, soil).clamp(0)\n",
    "            loss = loss_fn(targets, outputs)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            optimizer.step(closure)\n",
    "            \n",
    "            scheduler.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "            yt.append(targets.detach().cpu().numpy())\n",
    "            yp.append(outputs.detach().cpu().numpy())\n",
    "            \n",
    "        yt = np.concatenate(yt)\n",
    "        yp = np.concatenate(yp)\n",
    "        rmse_score = mean_squared_error(yt, yp, squared=False)\n",
    "        \n",
    "        losses = np.array(losses).mean()\n",
    "        vloss, yt, yp = validation(model, vloader, loss_fn)\n",
    "        vrmse_score = mean_squared_error(yt, yp, squared=False)\n",
    "        \n",
    "        figure = get_figure(yt, yp)\n",
    "        writer.add_figure(\"boxplot\", figure.get_figure(), global_step=epoch)\n",
    "        writer.add_scalars(\"Loss\", {\"train\" : losses, \"validation\" : vloss}, epoch)\n",
    "        writer.add_scalars(\"RMSE\", {\"train\" : rmse_score, \"validation\" : vrmse_score}, epoch)\n",
    "        \n",
    "        if best_metric > vrmse_score:\n",
    "            best_metric = vrmse_score\n",
    "            torch.save({\n",
    "                'model' : model.state_dict(),\n",
    "                'epoch' : epoch,\n",
    "                'metric' : best_metric,\n",
    "            },  f'{MODEL_PATH}/SnowNet_fold_{fold_idx}_best.pt')\n",
    "\n",
    "        print(raw_line.format(epoch, losses, rmse_score,\n",
    "                              vloss, vrmse_score, (time.time()-start_time)/60**1), file=logfile)    \n",
    "    torch.save({\n",
    "        'model' : model.state_dict(),\n",
    "        'epoch' : epoch,\n",
    "        'metric' : best_metric,\n",
    "    },  f'{MODEL_PATH}/SnowNet_fold_{fold_idx}_last.pt')\n",
    "    \n",
    "    return losses**0.5, best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36aadfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'X': target_values,\n",
    "          'y' : y }\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "params['groups'] = cell_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d18257",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start training model with fold #0\n",
      "\n",
      "                  Train | Valid\n",
      "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
      "\n",
      "     1│  95.554│   9.775│  70.354│   8.386│  1.74\n",
      "     2│  53.858│   7.339│  53.485│   7.314│  1.76\n",
      "     3│  42.605│   6.527│  43.874│   6.624│  1.82\n",
      "     4│  34.945│   5.911│  39.993│   6.327│  1.83\n",
      "     5│  29.412│   5.423│  39.808│   6.312│  1.83\n",
      "     6│  25.763│   5.076│  37.275│   6.108│  1.84\n",
      "     7│  22.492│   4.743│  31.789│   5.642│  1.83\n",
      "     8│  20.130│   4.487│  38.980│   6.248│  1.85\n",
      "     9│  17.901│   4.231│  30.952│   5.568│  1.85\n",
      "    10│  16.206│   4.026│  32.748│   5.728│  1.84\n",
      "    11│  14.781│   3.845│  30.886│   5.563│  1.85\n",
      "    12│  13.571│   3.684│  29.749│   5.459│  1.85\n",
      "    13│  12.525│   3.539│  31.110│   5.584│  1.85\n",
      "    14│  11.434│   3.381│  27.705│   5.268│  1.85\n",
      "    15│  10.752│   3.279│  27.589│   5.258│  1.86\n",
      "    16│   9.887│   3.144│  27.457│   5.245│  1.86\n",
      "    17│   9.250│   3.041│  28.015│   5.298│  1.87\n",
      "    18│   8.641│   2.940│  28.174│   5.313│  1.87\n",
      "    19│   8.179│   2.860│  26.905│   5.192│  1.87\n",
      "    20│   7.652│   2.766│  27.934│   5.290│  1.86\n",
      "    21│   7.278│   2.698│  27.120│   5.213│  1.88\n",
      "    22│   7.063│   2.658│  27.583│   5.258│  1.86\n",
      "    23│   6.621│   2.573│  26.984│   5.200│  1.86\n",
      "    24│   6.440│   2.538│  27.020│   5.204│  1.86\n",
      "    25│   6.241│   2.498│  27.428│   5.242│  1.87\n",
      "    26│   6.006│   2.451│  26.869│   5.189│  1.87\n",
      "    27│   5.887│   2.426│  27.012│   5.203│  1.87\n",
      "    28│   5.858│   2.420│  26.980│   5.199│  1.86\n",
      "    29│   5.766│   2.401│  26.993│   5.201│  1.87\n",
      "    30│   5.748│   2.397│  26.885│   5.190│  1.87\n",
      "\n",
      " Start training model with fold #1\n",
      "\n",
      "                  Train | Valid\n",
      "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
      "\n",
      "     1│  90.066│   9.490│  55.724│   7.481│  1.81\n",
      "     2│  52.638│   7.255│  47.239│   6.887│  1.83\n",
      "     3│  42.491│   6.518│  40.004│   6.336│  1.84\n",
      "     4│  35.855│   5.988│  34.039│   5.842│  1.87\n",
      "     5│  30.025│   5.479│  31.466│   5.614│  1.86\n",
      "     6│  26.611│   5.159│  29.864│   5.471│  1.89\n",
      "     7│  23.208│   4.817│  29.735│   5.460│  1.87\n",
      "     8│  20.867│   4.568│  27.195│   5.221│  1.87\n",
      "     9│  18.433│   4.293│  26.386│   5.143│  1.87\n",
      "    10│  16.918│   4.113│  27.337│   5.236│  1.87\n",
      "    11│  15.471│   3.933│  25.172│   5.023│  1.87\n",
      "    12│  14.358│   3.789│  23.791│   4.885│  1.87\n",
      "    13│  13.092│   3.618│  23.759│   4.880│  1.88\n",
      "    14│  12.096│   3.478│  23.521│   4.856│  1.89\n",
      "    15│  11.507│   3.392│  22.738│   4.774│  1.89\n",
      "    16│  10.564│   3.250│  23.555│   4.859│  1.89\n",
      "    17│   9.852│   3.139│  22.440│   4.743│  1.89\n",
      "    18│   9.359│   3.059│  22.979│   4.799│  1.88\n",
      "    19│   8.737│   2.956│  22.272│   4.726│  1.89\n",
      "    20│   8.416│   2.901│  22.262│   4.725│  1.88\n",
      "    21│   8.044│   2.836│  22.647│   4.766│  1.89\n",
      "    22│   7.527│   2.743│  22.301│   4.729│  1.89\n",
      "    23│   7.287│   2.699│  22.653│   4.767│  1.89\n",
      "    24│   7.000│   2.646│  22.126│   4.711│  1.89\n",
      "    25│   6.768│   2.601│  21.785│   4.675│  1.90\n",
      "    26│   6.562│   2.562│  21.897│   4.686│  1.90\n",
      "    27│   6.443│   2.538│  21.803│   4.676│  1.92\n",
      "    28│   6.351│   2.520│  21.834│   4.680│  1.90\n",
      "    29│   6.364│   2.523│  22.018│   4.699│  1.88\n",
      "    30│   6.287│   2.507│  22.011│   4.699│  1.87\n",
      "\n",
      " Start training model with fold #2\n",
      "\n",
      "                  Train | Valid\n",
      "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
      "\n",
      "     1│  92.733│   9.630│  73.606│   8.580│  1.74\n",
      "     2│  54.307│   7.369│  57.255│   7.561│  1.85\n",
      "     3│  42.556│   6.523│  46.785│   6.836│  1.81\n",
      "     4│  35.378│   5.948│  42.082│   6.488│  1.80\n",
      "     5│  30.172│   5.493│  43.519│   6.599│  1.81\n",
      "     6│  26.414│   5.139│  42.564│   6.523│  1.82\n",
      "     7│  23.415│   4.839│  35.973│   5.998│  1.82\n",
      "     8│  20.884│   4.570│  40.229│   6.344│  1.82\n",
      "     9│  19.079│   4.368│  37.604│   6.133│  1.82\n",
      "    10│  17.228│   4.151│  35.207│   5.934│  1.83\n",
      "    11│  15.747│   3.968│  39.864│   6.317│  1.81\n",
      "    12│  14.187│   3.767│  33.790│   5.814│  1.81\n",
      "    13│  13.337│   3.652│  34.337│   5.862│  1.82\n",
      "    14│  12.453│   3.529│  32.296│   5.684│  1.82\n",
      "    15│  11.489│   3.390│  33.001│   5.746│  1.82\n",
      "    16│  10.622│   3.259│  33.794│   5.815│  1.80\n",
      "    17│  10.002│   3.163│  32.416│   5.695│  1.80\n",
      "    18│   9.309│   3.051│  31.783│   5.639│  1.79\n",
      "    19│   8.897│   2.983│  31.180│   5.585│  1.83\n",
      "    20│   8.303│   2.881│  31.648│   5.627│  1.81\n",
      "    21│   7.932│   2.816│  32.530│   5.705│  1.80\n",
      "    22│   7.619│   2.760│  32.002│   5.659│  1.79\n",
      "    23│   7.245│   2.692│  31.817│   5.642│  1.80\n",
      "    24│   6.917│   2.630│  32.156│   5.672│  1.80\n",
      "    25│   6.705│   2.589│  32.302│   5.685│  1.79\n",
      "    26│   6.529│   2.555│  31.430│   5.607│  1.79\n",
      "    27│   6.421│   2.534│  31.676│   5.629│  1.80\n",
      "    28│   6.296│   2.509│  31.775│   5.638│  1.79\n",
      "    29│   6.181│   2.486│  31.955│   5.654│  1.79\n",
      "    30│   6.179│   2.486│  31.883│   5.648│  1.80\n",
      "\n",
      " Start training model with fold #3\n",
      "\n",
      "                  Train | Valid\n",
      "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
      "\n",
      "     1│  89.715│   9.472│  66.011│   8.128│  1.77\n",
      "     2│  50.483│   7.105│  50.103│   7.079│  1.78\n",
      "     3│  40.210│   6.341│  45.082│   6.716│  1.80\n",
      "     4│  33.223│   5.764│  39.521│   6.288│  1.83\n",
      "     5│  28.365│   5.326│  38.547│   6.211│  1.81\n",
      "     6│  24.603│   4.960│  35.054│   5.921│  1.81\n",
      "     7│  21.719│   4.660│  35.935│   5.994│  1.82\n",
      "     8│  19.452│   4.410│  33.919│   5.827│  1.82\n",
      "     9│  17.580│   4.193│  31.524│   5.618│  1.83\n",
      "    10│  15.642│   3.955│  32.148│   5.672│  1.82\n",
      "    11│  14.375│   3.791│  36.858│   6.074│  1.82\n",
      "    12│  13.262│   3.642│  30.119│   5.490│  1.82\n",
      "    13│  12.084│   3.476│  32.722│   5.723│  1.81\n",
      "    14│  11.178│   3.343│  30.860│   5.557│  1.81\n",
      "    15│  10.450│   3.233│  30.010│   5.480│  1.81\n",
      "    16│   9.734│   3.120│  30.635│   5.535│  1.86\n",
      "    17│   9.020│   3.003│  30.785│   5.551│  1.84\n",
      "    18│   8.562│   2.926│  29.247│   5.411│  1.83\n",
      "    19│   8.016│   2.831│  29.968│   5.477│  1.83\n",
      "    20│   7.522│   2.743│  29.557│   5.439│  1.82\n",
      "    21│   7.267│   2.696│  28.768│   5.365│  1.83\n",
      "    22│   6.836│   2.615│  29.934│   5.473│  1.83\n",
      "    23│   6.484│   2.546│  29.204│   5.406│  1.83\n",
      "    24│   6.238│   2.498│  28.786│   5.367│  1.83\n",
      "    25│   6.052│   2.460│  28.663│   5.355│  1.84\n",
      "    26│   5.895│   2.428│  29.203│   5.406│  1.83\n",
      "    27│   5.680│   2.383│  29.045│   5.391│  1.83\n",
      "    28│   5.702│   2.388│  29.151│   5.401│  1.83\n",
      "    29│   5.581│   2.362│  28.813│   5.369│  1.84\n",
      "    30│   5.598│   2.366│  28.983│   5.386│  1.85\n",
      "\n",
      " Start training model with fold #4\n",
      "\n",
      "                  Train | Valid\n",
      "Epoch |  Loss  | Metric |  Loss  | Metric | Time, m\n",
      "\n",
      "     1│  97.484│   9.873│  74.608│   8.632│  1.76\n",
      "     2│  55.197│   7.429│  40.468│   6.363│  1.79\n",
      "     3│  44.649│   6.682│  51.514│   7.175│  1.79\n",
      "     4│  37.733│   6.143│  32.185│   5.677│  1.79\n",
      "     5│  32.081│   5.664│  29.483│   5.431│  1.79\n",
      "     6│  28.190│   5.309│  26.488│   5.150│  1.78\n",
      "     7│  25.051│   5.005│  26.533│   5.151│  1.79\n",
      "     8│  22.666│   4.761│  24.926│   4.994│  1.80\n",
      "     9│  20.047│   4.477│  25.458│   5.047│  1.81\n",
      "    10│  18.612│   4.314│  22.896│   4.786│  1.79\n",
      "    11│  16.690│   4.085│  23.161│   4.811│  1.81\n",
      "    12│  15.195│   3.898│  22.379│   4.730│  1.81\n",
      "    13│  14.061│   3.750│  22.981│   4.792│  1.82\n",
      "    14│  13.013│   3.607│  22.319│   4.721│  1.83\n",
      "    15│  12.259│   3.501│  21.395│   4.626│  1.84\n",
      "    16│  11.301│   3.362│  21.584│   4.644│  1.81\n",
      "    17│  10.577│   3.252│  23.074│   4.801│  1.81\n",
      "    18│   9.927│   3.151│  20.910│   4.569│  1.80\n",
      "    19│   9.307│   3.051│  21.854│   4.672│  1.80\n",
      "    20│   8.681│   2.946│  21.362│   4.618│  1.81\n",
      "    21│   8.234│   2.870│  20.438│   4.516│  1.80\n",
      "    22│   7.892│   2.809│  20.739│   4.550│  1.81\n",
      "    23│   7.604│   2.758│  20.421│   4.514│  1.81\n",
      "    24│   7.232│   2.689│  20.788│   4.555│  1.81\n",
      "    25│   7.138│   2.672│  20.828│   4.560│  1.81\n",
      "    26│   6.882│   2.623│  20.444│   4.518│  1.82\n",
      "    27│   6.740│   2.596│  20.408│   4.513│  1.82\n",
      "    28│   6.583│   2.566│  20.580│   4.532│  1.81\n",
      "    29│   6.555│   2.560│  20.537│   4.527│  1.81\n",
      "    30│   6.590│   2.567│  20.335│   4.505│  1.82\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(**params)):\n",
    "        \n",
    "    train_ds = SnowDataset(cell_idx[train_idx], data_idx[train_idx], xds)\n",
    "    valid_ds = SnowDataset(cell_idx[valid_idx], data_idx[valid_idx], xds)\n",
    "    \n",
    "    # define training and validation data loaders\n",
    "    loader = D.DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=8, drop_last=True)\n",
    "\n",
    "    vloader = D.DataLoader(\n",
    "                valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=f\"runs/SnowNet_Fold#{fold_idx:02d}\")\n",
    "    model = SnowNet(features=len(FEATURES), h_dim=H_DIM, width=WIDTH, timelag=TIMELAG)\n",
    "\n",
    "    base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "    optimizer = SAM(model.parameters(), base_optimizer, lr=LR, momentum=MOMENTUM)\n",
    "        \n",
    "    scheduler = get_cosine_schedule_with_warmup( #get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=len(loader)*EPOCHES, min_coef=0., last_epoch=-1)\n",
    "    \n",
    "    print(f'\\n Start training model with fold #{fold_idx}', file=logfile)\n",
    "\n",
    "    loss, vloss = train_loop(model, optimizer, scheduler, loader, vloader, EPOCHES, fold_idx)\n",
    "    \n",
    "    inputs = train_ds[0]\n",
    "    inputs = [torch.from_numpy(i[None]) for i in inputs[:-1]]\n",
    "    writer.add_graph(model, input_to_model=inputs)\n",
    "    \n",
    "    writer.add_hparams({'lr': LR,\n",
    "                        'momentum': MOMENTUM,\n",
    "                        'bsize': BATCH_SIZE,\n",
    "                        'wdecay' : WEIGHT_DECAY,\n",
    "                        'warmup': WARMUP_STEPS,\n",
    "                        'clip_norm' : CLIP_NORM,\n",
    "                        'seed' : SEED,\n",
    "                        'epoches': EPOCHES,\n",
    "                        'hdim' : H_DIM,\n",
    "                        'width': WIDTH,\n",
    "                        'timelag' : TIMELAG,\n",
    "                        'fold_idx' : fold_idx,\n",
    "                        'features' : \" \".join(FEATURES),\n",
    "                       },\n",
    "                      {'hparam/loss': loss, 'hparam/vloss': vloss})\n",
    "    writer.close()\n",
    "\n",
    "    del model, optimizer, scheduler, loader, vloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c904d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
