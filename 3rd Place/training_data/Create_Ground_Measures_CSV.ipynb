{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66e5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to generate ground_measures_data.csv (from Snowcast data files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7d8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Python Environment\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebfb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Metadata for the Ground Features (for the Evaluation stage)\n",
    "\n",
    "ground_feature_ids = []\n",
    "with open('Data/Snowcast Evaluation/ground_measures_metadata.csv') as f:\n",
    "    tline = f.readline().replace('\\n','')\n",
    "    header = tline.split(',')\n",
    "    tline = f.readline()\n",
    "    \n",
    "    # Read the IDs (so we can match with features from the development stage)\n",
    "    while not (tline == ''):\n",
    "        fields = tline.split(',')\n",
    "        id = fields[0]\n",
    "        ground_feature_ids.append(id)\n",
    "        tline = f.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a980b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Development Stage Ground Features (Training Dataset)\n",
    "\n",
    "# Get the timestamp information and ground feature ids\n",
    "development_feature_ids = []\n",
    "with open('Data/Snowcast Development/ground_measures_train_features.csv') as f:\n",
    "    tline = f.readline().replace('\\n','')\n",
    "    header = tline.split(',')\n",
    "    tline = f.readline()\n",
    "    while not (tline == ''):\n",
    "        fields = tline.split(',')\n",
    "        id = fields[0]\n",
    "        development_feature_ids.append(id)\n",
    "        tline = f.readline()\n",
    "\n",
    "development_feature_ids = np.array(development_feature_ids)  # So we can do numpy stuff to it\n",
    "times_train = np.array(header[1:])\n",
    "\n",
    "num_times = len(times_train)\n",
    "num_lines = len(development_feature_ids)\n",
    "development_GroundSWE = np.empty([num_lines, num_times])\n",
    "development_GroundSWE[:] = np.nan\n",
    "\n",
    "# Read the data\n",
    "with open('Data/Snowcast Development/ground_measures_train_features.csv') as f:\n",
    "    tline = f.readline()\n",
    "    tline = f.readline()\n",
    "    while not (tline == ''):\n",
    "        fields = tline.split(',')\n",
    "        id = fields[0]\n",
    "        loc = development_feature_ids == id\n",
    "        for d in range(len(fields)-1):\n",
    "            if not (fields[d+1] == '') and len(fields[d+1]) > 1:\n",
    "                development_GroundSWE[loc,d] = float(fields[d+1])\n",
    "                \n",
    "        tline = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d44a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Development Stage Ground Features (Test Dataset)\n",
    "\n",
    "# Get the timestamp information\n",
    "with open('Data/Snowcast Development/ground_measures_test_features.csv') as f:\n",
    "    tline = f.readline().replace('\\n','')\n",
    "    header = tline.split(',')\n",
    "    \n",
    "times_test = np.array(header[1:])\n",
    "\n",
    "num_times = len(times_test)\n",
    "num_lines = len(development_feature_ids)\n",
    "development_GroundSWE_test = np.empty([num_lines, num_times])\n",
    "development_GroundSWE_test[:] = np.nan\n",
    "\n",
    "# Read the data\n",
    "with open('Data/Snowcast Development/ground_measures_test_features.csv') as f:\n",
    "    tline = f.readline()\n",
    "    tline = f.readline()\n",
    "    while not (tline == ''):\n",
    "        fields = tline.split(',')\n",
    "        id = fields[0]\n",
    "        loc = development_feature_ids == id\n",
    "        for d in range(len(fields)-1):\n",
    "            if not (fields[d+1] == '') and len(fields[d+1]) > 1:\n",
    "                development_GroundSWE_test[loc,d] = float(fields[d+1])\n",
    "                \n",
    "        tline = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c75746",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the Development Stage Datasets and Write Output File\n",
    "\n",
    "## Combine time vectors and SWE data\n",
    "development_GroundTimes = np.concatenate((times_train, times_test))\n",
    "development_GroundSWE = np.concatenate((development_GroundSWE, development_GroundSWE_test), axis=1)\n",
    "\n",
    "## Write the output file\n",
    "f = open('Training Tables/ground_measures_data.csv', 'w')\n",
    "\n",
    "# Write the first line\n",
    "f.write('station_id')\n",
    "for time in development_GroundTimes:\n",
    "    f.write(',' + time)\n",
    "f.write('\\n')\n",
    "\n",
    "# For subsequent lines, write the cell id and then the data for each date\n",
    "for ground_feature_id in ground_feature_ids:\n",
    "    loc = development_feature_ids == ground_feature_id\n",
    "    f.write(ground_feature_id)\n",
    "    for d in range(len(development_GroundTimes)):\n",
    "        if np.any(loc):\n",
    "            f.write(',{:.2f}'.format(development_GroundSWE[loc, d][0]))\n",
    "        else:\n",
    "            f.write(',nan')\n",
    "    f.write('\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae3cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
