{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waVk6taWlvR7"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install libgdal-dev gdal-bin python-gdal python-numpy python-scipy -y\n",
        "!pip install wget\n",
        "!pip install azure-storage-blob\n",
        "!pip install pyproj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hulA24FNQ1m5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8ViTTAaQ6H6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import tempfile\n",
        "import wget\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdal\n",
        "import osr\n",
        "\n",
        "from azure.storage.blob import ContainerClient\n",
        "from pyproj import Proj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IezUf5ccSSn6"
      },
      "source": [
        "## Import Base Data Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lg6EdLiRZ8_"
      },
      "outputs": [],
      "source": [
        "ground_measures_metadata = pd.read_csv('/content/drive/MyDrive/snocast/eval/data/ground_measures_metadata.csv')\n",
        "submission_format = pd.read_csv('/content/drive/MyDrive/snocast/eval/data/submission_format.csv')\n",
        "run_date = '2022-06-30'\n",
        "lookback = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0GJtFEFR7mj"
      },
      "outputs": [],
      "source": [
        "# get latitude longitude for grids\n",
        "f = open('/content/drive/MyDrive/snocast/eval/data/grid_cells.geojson')\n",
        "grid_cells = json.load(f)\n",
        "print('length grid_cells features: ', len(grid_cells['features']))\n",
        "\n",
        "ids = []\n",
        "lats = []\n",
        "lons = []\n",
        "bboxes = []\n",
        "coords = []\n",
        "\n",
        "for grid_cell in grid_cells['features']:\n",
        "    cell_id = grid_cell['properties']['cell_id']\n",
        "    coordinates = grid_cell['geometry']['coordinates'][0][1:]\n",
        "    lon, lat = np.mean(coordinates, axis=0)\n",
        "    northeast_corner = np.max(coordinates, axis=0)\n",
        "    southwest_corner = np.min(coordinates, axis=0)\n",
        "    # bbox = [min_lon, min_lat, max_lon, max_lat]\n",
        "    bbox = np.concatenate([southwest_corner,northeast_corner])\n",
        "    ids.append(cell_id)\n",
        "    lats.append(lat)\n",
        "    lons.append(lon)\n",
        "    bboxes.append(bbox)\n",
        "    coords.append(coordinates)\n",
        "\n",
        "grid_cells_pd = pd.DataFrame({'location_id': ids, \n",
        "                             'latitude': lats, \n",
        "                             'longitude': lons, \n",
        "                             'bbox': bboxes,\n",
        "                             'coordinates': coords})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5xI0uzJFbvr"
      },
      "source": [
        "### Setup Environment to Download Modis Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z2IQlUr-RM5"
      },
      "outputs": [],
      "source": [
        "modis_account_name = 'modissa'\n",
        "modis_container_name = 'modis-006'\n",
        "modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n",
        "modis_blob_root = modis_account_url + modis_container_name + '/'\n",
        "\n",
        "# This file is provided by NASA; it indicates the lat/lon extents of each\n",
        "# MODIS tile.\n",
        "#\n",
        "# The file originally comes from:\n",
        "#\n",
        "# https://modis-land.gsfc.nasa.gov/pdf/sn_bound_10deg.txt\n",
        "modis_tile_extents_url = modis_blob_root + 'sn_bound_10deg.txt'\n",
        "\n",
        "temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n",
        "os.makedirs(temp_dir,exist_ok=True)\n",
        "fn = os.path.join(temp_dir,modis_tile_extents_url.split('/')[-1])\n",
        "wget.download(modis_tile_extents_url, fn)\n",
        "\n",
        "# Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n",
        "modis_tile_extents = np.genfromtxt(fn,\n",
        "                     skip_header = 7, \n",
        "                     skip_footer = 3)\n",
        "\n",
        "# modis_container_name = 'modis-061'\n",
        "# modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n",
        "# modis_blob_root = modis_account_url + modis_container_name + '/'\n",
        "\n",
        "modis_container_client = ContainerClient(account_url=modis_account_url, \n",
        "                                         container_name=modis_container_name,\n",
        "                                         credential=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg8cIPOsGGdc"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYs19q9C-JKk"
      },
      "outputs": [],
      "source": [
        "# https://gis.stackexchange.com/questions/265400/getting-tile-number-of-sinusoidal-modis-product-from-lat-long\n",
        "CELLS = 2400\n",
        "VERTICAL_TILES = 18\n",
        "HORIZONTAL_TILES = 36\n",
        "EARTH_RADIUS = 6371007.181\n",
        "EARTH_WIDTH = 2 * np.pi * EARTH_RADIUS\n",
        "\n",
        "MODIS_GRID = Proj(f'+proj=sinu +R={EARTH_RADIUS} +nadgrids=@null +wktext')\n",
        "\n",
        "TILE_WIDTH = EARTH_WIDTH / HORIZONTAL_TILES\n",
        "TILE_HEIGHT = TILE_WIDTH\n",
        "CELL_SIZE = TILE_WIDTH / CELLS\n",
        "def lat_lon_to_modis_tile(lat, lon):\n",
        "    x, y = MODIS_GRID(lon, lat)\n",
        "    h = (EARTH_WIDTH * .5 + x) / TILE_WIDTH\n",
        "    v = -(EARTH_WIDTH * .25 + y - (VERTICAL_TILES - 0) * TILE_HEIGHT) / TILE_HEIGHT\n",
        "    return int(h), int(v)\n",
        "\n",
        "\n",
        "def list_blobs_in_folder(container_name,folder_name):\n",
        "    \"\"\"\n",
        "    List all blobs in a virtual folder in an Azure blob container\n",
        "    \"\"\"\n",
        "    \n",
        "    files = []\n",
        "    generator = modis_container_client.list_blobs(name_starts_with=folder_name)\n",
        "    for blob in generator:\n",
        "        files.append(blob.name)\n",
        "    return files\n",
        "        \n",
        "    \n",
        "def list_hdf_blobs_in_folder(container_name,folder_name):\n",
        "    \"\"\"\"\n",
        "    List .hdf files in a folder\n",
        "    \"\"\"\n",
        "    \n",
        "    files = list_blobs_in_folder(container_name,folder_name)\n",
        "    files = [fn for fn in files if fn.endswith('.hdf')]\n",
        "    return files \n",
        "\n",
        "def clip_nan(value):\n",
        "  if value > 100:\n",
        "    return np.nan\n",
        "  return value\n",
        "\n",
        "def get_modis_tile_dataset(product, h, v, daynum):\n",
        "  folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + daynum\n",
        "\n",
        "  # Find all HDF files from this tile on this day\n",
        "  filenames = list_hdf_blobs_in_folder(modis_container_name, folder)\n",
        "  print('Found {} matching file(s):'.format(len(filenames)))\n",
        "  for fn in filenames:\n",
        "      print(fn)\n",
        "\n",
        "  # Work with the first returned URL\n",
        "  blob_name = filenames[0]\n",
        "\n",
        "  # Download to a temporary file\n",
        "  url = modis_blob_root + blob_name\n",
        "\n",
        "  fn = os.path.join(data_dir,blob_name.replace('/','_'))\n",
        "  if not os.path.isfile(fn):\n",
        "      wget.download(url,fn)\n",
        "\n",
        "  ds = gdal.Open(fn, gdal.GA_ReadOnly)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def get_ndsi_value(dataset, x, y):\n",
        "  # https://gis.stackexchange.com/questions/221292/retrieve-pixel-value-with-geographic-coordinate-as-input-with-gdal\n",
        "  cols = dataset.RasterXSize\n",
        "  rows = dataset.RasterYSize\n",
        "\n",
        "  transform = dataset.GetGeoTransform()\n",
        "\n",
        "  xOrigin = transform[0]\n",
        "  yOrigin = transform[3]\n",
        "  pixelWidth = transform[1]\n",
        "  pixelHeight = -transform[5]\n",
        "\n",
        "  data = dataset.ReadAsArray(0, 0, cols, rows)\n",
        "\n",
        "  data_col = int((x - xOrigin) / pixelWidth)\n",
        "  data_row = int((yOrigin - y) / pixelHeight)\n",
        "\n",
        "  try:\n",
        "    ndsi_value = data[data_row][data_col]\n",
        "  except:\n",
        "    print('exception')\n",
        "    ndsi_value = np.nan\n",
        "\n",
        "  return clip_nan(ndsi_value)\n",
        "\n",
        "def modis_projection_func(dataset):\n",
        "        srs_wkt = dataset.GetProjection()  # gives SRS in WKT\n",
        "        srs_converter = osr.SpatialReference()  # makes an empty spatial ref object\n",
        "        srs_converter.ImportFromWkt(srs_wkt)  # populates the spatial ref object with our WKT SRS\n",
        "        projection = srs_converter.ExportToProj4()\n",
        "        p_modis_grid = Proj(projection) # '+proj=sinu +R=6371007.181 +nadgrids=@null +wktext'\n",
        "        return p_modis_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af9E-o1VGNIP"
      },
      "source": [
        "### Access and Plot Modis Tile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGkChD2VB-e1"
      },
      "outputs": [],
      "source": [
        "cell_modis_tiles_h = []\n",
        "cell_modis_tiles_v = []\n",
        "for idx, row in grid_cells_pd.iterrows():\n",
        "  lat, lon = row[['latitude','longitude']].values\n",
        "  h, v = lat_lon_to_modis_tile(lat, lon)\n",
        "  cell_modis_tiles_h.append(h)\n",
        "  cell_modis_tiles_v.append(v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deQP9-fRC-2d"
      },
      "outputs": [],
      "source": [
        "grid_cells_pd['h_tile'] = cell_modis_tiles_h\n",
        "grid_cells_pd['v_tile'] = cell_modis_tiles_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVl52CfJVVt"
      },
      "outputs": [],
      "source": [
        "grid_cells_pd.groupby(['h_tile','v_tile']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVFizdg1NthH"
      },
      "source": [
        "## Get NDSI_Snow_Cover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIIS_2R1mC2_"
      },
      "outputs": [],
      "source": [
        "max_date = datetime.strptime(run_date,'%Y-%m-%d')\n",
        "date_list = [(max_date - timedelta(days=x)).strftime('%Y-%m-%d') for x in range(lookback+1)]\n",
        "print(date_list)\n",
        "tile_list = [(8,4), (8,5), (9,4), (9,5), (10,4)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErSSs_28lPFx"
      },
      "source": [
        "If this is the first time this batch job is run for a given `run_date` then it will pull data for all of the dates in the date list.\n",
        "\n",
        "If this batch job has been previously run for a given `run_date`, then the job will look for existing files and pull data from where those files left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5azBvT_5hGyf"
      },
      "outputs": [],
      "source": [
        "fresh_run = True\n",
        "try:\n",
        "  terra_df = pd.read_parquet(f'/content/drive/MyDrive/snocast/eval/data/modis/modis_terra_pc_{run_date}.parquet')\n",
        "  aqua_df = pd.read_parquet(f'/content/drive/MyDrive/snocast/eval/data/modis/modis_aqua_pc_{run_date}.parquet')\n",
        "  max_terra = terra_df.date.max()\n",
        "  max_aqua = aqua_df.date.max()\n",
        "  print(\"Max Terra: \", max_terra, \"Min Aqua: \", max_aqua)\n",
        "  terra_date_list = [d for d in date_list if d > max_terra]\n",
        "  aqua_date_list = [d for d in date_list if d > max_aqua]\n",
        "  fresh_run = False\n",
        "except:\n",
        "  print(\"Fresh Run\")\n",
        "  terra_date_list = date_list\n",
        "  aqua_date_list = date_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlitHkmjnDh5"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/snocast/eval/data/modis_data_raw'\n",
        "\n",
        "terra_list = []\n",
        "terra_ids = []\n",
        "terra_dates = []\n",
        "terra_lats = []\n",
        "terra_lons = []\n",
        "\n",
        "aqua_list = []\n",
        "aqua_ids = []\n",
        "aqua_dates = []\n",
        "aqua_lats = []\n",
        "aqua_lons = []\n",
        "\n",
        "for pull_date in date_list:\n",
        "  print(pull_date)\n",
        "  for tile in tile_list:\n",
        "    h, v = tile\n",
        "    print(h, v)\n",
        "    daynum = run_date[0:4] + datetime.strptime(pull_date, '%Y-%m-%d').strftime('%j')\n",
        "    tile_grid_cells = grid_cells_pd[(grid_cells_pd['h_tile'] == h) & (grid_cells_pd['v_tile'] == v)]\n",
        "\n",
        "    get_terra = False\n",
        "    get_aqua = False\n",
        "\n",
        "    if pull_date in terra_date_list:\n",
        "      try:\n",
        "        terra_ds = get_modis_tile_dataset('MOD10A1', h, v, daynum)\n",
        "        terra_snow_cover = gdal.Open(terra_ds.GetSubDatasets()[0][0], gdal.GA_ReadOnly)\n",
        "        p_modis_grid = modis_projection_func(terra_snow_cover)\n",
        "        get_terra = True\n",
        "      except:\n",
        "        print(f'No Terra file for {h}, {v}, {pull_date}')\n",
        "\n",
        "\n",
        "    if pull_date in aqua_date_list:\n",
        "      try:\n",
        "        aqua_ds = get_modis_tile_dataset('MYD10A1', h, v, daynum)\n",
        "        aqua_snow_cover = gdal.Open(aqua_ds.GetSubDatasets()[0][0], gdal.GA_ReadOnly)\n",
        "        p_modis_grid = modis_projection_func(aqua_snow_cover)\n",
        "        get_aqua = True\n",
        "      except:\n",
        "        print(f'No Aqua file for {h}, {v}, {pull_date}')\n",
        "\n",
        "\n",
        "    if get_terra or get_aqua:\n",
        "      for idx, row in tile_grid_cells.iterrows():\n",
        "        for lon, lat in row['coordinates']+[[row['longitude'], row['latitude']]]:\n",
        "          x, y = p_modis_grid(lon, lat)\n",
        "\n",
        "          if get_terra:\n",
        "            terra_list.append(get_ndsi_value(terra_snow_cover, x, y))\n",
        "            terra_ids.append(row['location_id'])\n",
        "            terra_dates.append(pull_date)\n",
        "            terra_lats.append(lat)\n",
        "            terra_lons.append(lon)\n",
        "\n",
        "          if get_aqua:\n",
        "            aqua_list.append(get_ndsi_value(aqua_snow_cover, x, y))\n",
        "            aqua_ids.append(row['location_id'])\n",
        "            aqua_dates.append(pull_date)\n",
        "            aqua_lats.append(lat)\n",
        "            aqua_lons.append(lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OgwM0Llz9HD"
      },
      "outputs": [],
      "source": [
        "if fresh_run:\n",
        "  terra_df = pd.DataFrame({'NDSI_Snow_Cover': terra_list,\n",
        "                          'location_id': terra_ids,\n",
        "                          'date': terra_dates,\n",
        "                          'latitude': terra_lats,\n",
        "                          'longitude': terra_lons})\n",
        "\n",
        "  aqua_df = pd.DataFrame({'NDSI_Snow_Cover': aqua_list,\n",
        "                          'location_id': aqua_ids,\n",
        "                          'date': aqua_dates,\n",
        "                          'latitude': aqua_lats,\n",
        "                          'longitude': aqua_lons})\n",
        "else:\n",
        "  if len(terra_list) > 0:\n",
        "    print(\"new Terra data!\")\n",
        "    new_terra_df = pd.DataFrame({'NDSI_Snow_Cover': terra_list,\n",
        "                            'location_id': terra_ids,\n",
        "                            'date': terra_dates,\n",
        "                            'latitude': terra_lats,\n",
        "                            'longitude': terra_lons})\n",
        "    \n",
        "    terra_df = pd.concat([terra_df, new_terra_df])\n",
        "\n",
        "  if len(aqua_list) > 0:\n",
        "    print(\"new Aqua data!\")\n",
        "    new_aqua_df = pd.DataFrame({'NDSI_Snow_Cover': aqua_list,\n",
        "                            'location_id': aqua_ids,\n",
        "                            'date': aqua_dates,\n",
        "                            'latitude': aqua_lats,\n",
        "                            'longitude': aqua_lons})\n",
        "    aqua_df = pd.concat([aqua_df, new_aqua_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8C5h6Ysu_DR"
      },
      "outputs": [],
      "source": [
        "terra_df.groupby('date').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x9erhoDMi7v"
      },
      "outputs": [],
      "source": [
        "aqua_df.groupby('date').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXf10bSI0eGM"
      },
      "outputs": [],
      "source": [
        "terra_df.to_parquet(f'/content/drive/MyDrive/snocast/eval/data/modis/modis_terra_pc_{run_date}.parquet')\n",
        "aqua_df.to_parquet(f'/content/drive/MyDrive/snocast/eval/data/modis/modis_aqua_pc_{run_date}.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WksQ7fRlE965"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "get_modis_pc_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}