{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCfpyIKG_Ntc"
      },
      "outputs": [],
      "source": [
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqOkTpVfCvi7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muqUwpX4_9o7"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import botocore\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import netCDF4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC-cnuT5_c07"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = 'drivendata-public-assets'\n",
        "\n",
        "# enter authentication credentials\n",
        "s3 = boto3.resource('s3', aws_access_key_id = 'aws_access_key_id', \n",
        "                          aws_secret_access_key = 'aws_secret_access_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P6fzkzF_cwW"
      },
      "outputs": [],
      "source": [
        "KEY = 'land_cover_map.tar.gz'\n",
        "\n",
        "try:\n",
        "  s3.Bucket(BUCKET_NAME).download_file(KEY, 'land_cover_map.tar.gz')\n",
        "  \n",
        "except botocore.exceptions.ClientError as e:\n",
        "  if e.response['Error']['Code'] == \"404\":\n",
        "    print(\"The object does not exist.\")\n",
        "  else:\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UviWh1g2_ctX"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/land_cover_map.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Ky6z0TjC4n"
      },
      "outputs": [],
      "source": [
        "!cp /content/C3S-LC-L4-LCCS-Map-300m-P1Y-2020-v2.1.1.nc /content/drive/MyDrive/snocast/eval/data/static/C3S-LC-L4-LCCS-Map-300m-P1Y-2020-v2.1.1.nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99XBnoFlFMBQ"
      },
      "outputs": [],
      "source": [
        "fp='/content/drive/MyDrive/snocast/eval/data/static/C3S-LC-L4-LCCS-Map-300m-P1Y-2020-v2.1.1.nc' # your file name with the eventual path\n",
        "nc = netCDF4.Dataset(fp) # reading the nc file and creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of9VYyarFRlQ"
      },
      "outputs": [],
      "source": [
        "# http://maps.elie.ucl.ac.be/CCI/viewer/download/ESACCI-LC-QuickUserGuide-LC-Maps_v2-0-7.pdf\n",
        "lccs_class = nc.variables['lccs_class']\n",
        "lccs_lat = np.array(nc.variables['lat'])\n",
        "lccs_lon = np.array(nc.variables['lon'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUIQBQ-UI_Z0"
      },
      "source": [
        "### Import Base Data Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mshiRZnECY4C"
      },
      "outputs": [],
      "source": [
        "ground_measures_metadata = pd.read_csv('/content/drive/MyDrive/snocast/eval/data/ground_measures_metadata.csv')\n",
        "submission_format = pd.read_csv('/content/drive/MyDrive/snocast/eval/data/submission_format.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTsNZvsjy5Fk"
      },
      "outputs": [],
      "source": [
        "# get latitude longitude for grids\n",
        "f = open('/content/drive/MyDrive/snocast/eval/data/grid_cells.geojson')\n",
        "grid_cells = json.load(f)\n",
        "print('length grid_cells features: ', len(grid_cells['features']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBpi19GiERNQ"
      },
      "outputs": [],
      "source": [
        "ids = []\n",
        "lats = []\n",
        "lons = []\n",
        "bboxes = []\n",
        "\n",
        "for grid_cell in grid_cells['features']:\n",
        "    cell_id = grid_cell['properties']['cell_id']\n",
        "    coordinates = grid_cell['geometry']['coordinates'][0]\n",
        "    lon, lat = np.mean(coordinates, axis=0)\n",
        "    northeast_corner = np.max(coordinates, axis=0)\n",
        "    southwest_corner = np.min(coordinates, axis=0)\n",
        "    # bbox = [min_lon, min_lat, max_lon, max_lat]\n",
        "    bbox = np.concatenate([southwest_corner,northeast_corner])\n",
        "    ids.append(cell_id)\n",
        "    lats.append(lat)\n",
        "    lons.append(lon)\n",
        "    bboxes.append(bbox)\n",
        "\n",
        "grid_cells_pd = pd.DataFrame({'location_id': ids, \n",
        "                             'latitude': lats, \n",
        "                             'longitude': lons, \n",
        "                             'bbox': bboxes})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSCG8E0RUJHs"
      },
      "outputs": [],
      "source": [
        "all_max_lat = grid_cells_pd.latitude.max()\n",
        "all_min_lat = grid_cells_pd.latitude.min()\n",
        "all_max_lon = grid_cells_pd.longitude.max()\n",
        "all_min_lon = grid_cells_pd.longitude.min()\n",
        "print(all_min_lon, all_min_lat, all_max_lon, all_max_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhyq74qBOpRH"
      },
      "outputs": [],
      "source": [
        "# Figure out how to trim to only relevant lat lon\n",
        "lccs_lat_values = (lccs_lat < all_max_lat) & (lccs_lat > all_min_lat)\n",
        "lccs_lon_values = (lccs_lon < all_max_lon) & (lccs_lon > all_min_lon)\n",
        "\n",
        "reduced_lccs = np.squeeze(lccs_class[:, lccs_lat_values, lccs_lon_values])\n",
        "reduced_lat = lccs_lat[lccs_lat_values]\n",
        "reduced_lon = lccs_lon[lccs_lon_values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2S0m1da1WXl"
      },
      "outputs": [],
      "source": [
        "lccs_arr = []\n",
        "\n",
        "for idx, row in grid_cells_pd.iterrows():\n",
        "  if idx % 100 == 0:\n",
        "    print(idx)\n",
        "  min_lon, min_lat, max_lon, max_lat = row['bbox']\n",
        "\n",
        "  lat_values = (reduced_lat < max_lat) & (reduced_lat > min_lat)\n",
        "  lon_values = (reduced_lon < max_lon) & (reduced_lon > min_lon)\n",
        "  mask = lon_values[np.newaxis, :] & lat_values[:, np.newaxis]\n",
        "\n",
        "  arr = reduced_lccs[mask]\n",
        "  lccs_cat, lccs_count = np.unique(arr, return_counts=True)\n",
        "  lccs_len = len(arr)\n",
        "\n",
        "  land_cover = {}\n",
        "  land_cover['location_id'] = row['location_id']\n",
        "  lccs_order = np.flip(np.argsort(lccs_count))\n",
        "  for i in range(3):\n",
        "    if i+1 <= len(lccs_order):\n",
        "      land_cover[f'lccs_{i}'] = lccs_cat[lccs_order[i]]\n",
        "      land_cover[f'lccs_pct_{i}'] = lccs_count[lccs_order[i]]/lccs_len\n",
        "    else:\n",
        "      land_cover[f'lccs_{i}'] = 0\n",
        "      land_cover[f'lccs_pct_{i}'] = np.nan\n",
        "  \n",
        "  lccs_arr.append(land_cover)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTr6K_Nx4NWs"
      },
      "outputs": [],
      "source": [
        "print(idx)\n",
        "print(len(lccs_arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jtln4oJFm_Q"
      },
      "outputs": [],
      "source": [
        "lccs_df = pd.DataFrame(lccs_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKQ1GRT8I7Pp"
      },
      "outputs": [],
      "source": [
        "lccs_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GdT3xQ-4qDG"
      },
      "outputs": [],
      "source": [
        "lccs_df.to_parquet('/content/drive/MyDrive/snocast/eval/data/static/grid_lccs.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDvOkgThvq7t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "get_lccs_eval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
